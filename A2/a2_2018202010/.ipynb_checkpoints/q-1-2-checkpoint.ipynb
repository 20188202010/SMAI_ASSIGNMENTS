{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes classifier on Loan dataset to help bank achieve its goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"LoanDataset/data.csv\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes:\n",
    "\n",
    "ID - A unique identifier <br/>\n",
    "Age <br/>\n",
    "Number of years of experience <br/>\n",
    "Annual Income <br/>\n",
    "ZIPCode <br/>\n",
    "Family size <br/>\n",
    "Avgerage spending per month <br/>\n",
    "Education Level. 1: 12th; 2: Graduate; 3: Post Graduate <br/>\n",
    "Mortgage Value of house if any <br/>\n",
    "Did this customer accept the personal loan offered in the last campaign? -- Output label <br/>\n",
    "Does the customer have a securities account with the bank? <br/>\n",
    "Does the customer have a certificate of deposit (CD) account with the bank? <br/>\n",
    "Does the customer use internet banking facilities? <br/>\n",
    "Does the customer uses a credit card issued by UniversalBank? <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = ['id', 'age', 'exp', 'income', 'zip', 'fam_size', 'spending', 'education', 'mortgage', 'loan_accept', 'securities_account', 'certi_dep', 'net_banking', 'UniversalBank_cc']\n",
    "numerical = ['age', 'exp', 'income', 'fam_size', 'spending', 'mortgage']\n",
    "categorical = ['education', 'securities_account', 'certi_dep', 'net_banking', 'UniversalBank_cc']\n",
    "dataset = dataset.drop(dataset.index[0])\n",
    "# rows , cols = dataset.shape\n",
    "target = 'loan_accept'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = np.split(dataset, [int(.8*len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = train[train[target]==0]\n",
    "target1 = train[train[target]==1]\n",
    "\n",
    "total_len = train.shape[0]\n",
    "\n",
    "total_zero = target0.shape[0]\n",
    "total_one = target1.shape[0]\n",
    "\n",
    "p0 = float(total_zero)/total_len\n",
    "p1 = float(total_one)/total_len\n",
    "\n",
    "prob_ca = {}\n",
    "prob_nu = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numCalc():\n",
    "    #{ age: [ [mean0, std0], [mean1,std1] ]}\n",
    "    for colName in numerical:\n",
    "        zeros = [] #list to store mean, std for 0 class\n",
    "        ones = [] #list to store mean, std for 1 class\n",
    "        summary = [] #combined list of 0 and 1 class mean, std\n",
    "        zeroClass = target0[colName] #eg temp = 66, play = no\n",
    "        oneClass = target1[colName] #eg temp = 66, play = yes\n",
    "\n",
    "        mean0 = zeroClass.mean()\n",
    "        mean1 = oneClass.mean()\n",
    "        ones.append(mean1) #mean of 1 class\n",
    "        zeros.append(mean0)\n",
    "\n",
    "        std0 = zeroClass.std()\n",
    "        std1 = oneClass.std()\n",
    "        ones.append(std1)\n",
    "        zeros.append(std0)\n",
    "\n",
    "        # summary: [ <zeros>, <ones>]\n",
    "\n",
    "        summary.append(zeros)\n",
    "        summary.append(ones)\n",
    "        \n",
    "        prob_nu[colName] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCalc()\n",
    "# print prob_nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catCalc():\n",
    "    #{ <humidity>: [ {<low>: [p0, p1], <medium>: [p0, p1], <high>: [p0, p1]} ] }\n",
    "    for colName in categorical:\n",
    "        summary = [] #combined list of 0 and 1 class prob for all unique values of that column\n",
    "        unique_val = train[colName].unique()\n",
    "        sub_dict = {}\n",
    "        for val in unique_val:\n",
    "            \n",
    "            sub_summary = [] #list of 0 and 1 class prob for that particular unique val\n",
    "            val_df = train[train[colName] == val] #eg outlook = sunny\n",
    "\n",
    "            zeroClass = val_df[val_df[target] == 0] #sunny , play = no\n",
    "            oneClass = val_df[val_df[target] == 1] #sunny , play = yes\n",
    "\n",
    "            num_zero = zeroClass.shape[0]\n",
    "            num_one = oneClass.shape[0]\n",
    "\n",
    "            prob_zero = float(num_zero)/total_zero\n",
    "            prob_one = float(num_one)/total_one\n",
    "            sub_summary.append(prob_zero)\n",
    "            sub_summary.append(prob_one)\n",
    "#             print \"colName: \",colName,\"val: \",val,\"subSum: \",sub_summary\n",
    "            sub_dict[val] = sub_summary\n",
    "#             print \"sub_dict: \",sub_dict\n",
    "        summary.append(sub_dict)\n",
    "#         print \"summary: \",summary\n",
    "        prob_ca[colName] = summary\n",
    "            \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCalc()\n",
    "# print prob_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numProb(sd,x,mean):\n",
    "    constant = math.sqrt(2*3.14)\n",
    "    den = constant*sd\n",
    "    \n",
    "    num = (x - mean)**2\n",
    "    power =  -1 * float (num) / ( 2 * (sd**2) )\n",
    "    \n",
    "    ans = float( math.exp(power))/ den\n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, default=0):\n",
    "    likelihood_1 = 0\n",
    "    likelihood_0 = 0\n",
    "    \n",
    "    for colName, colVal in row.items():\n",
    "\n",
    "        lognP0 =0\n",
    "        lognP1 =0\n",
    "        logcP0 =0\n",
    "        logcP1 =0\n",
    "        \n",
    "        if colName in numerical:  #{ age: [ [mean0, std0], [mean1,std1] ]}\n",
    "            mean0 = prob_nu[colName][0][0]\n",
    "            mean1 = prob_nu[colName][1][0]\n",
    "            std0 = prob_nu[colName][0][1]\n",
    "            std1 = prob_nu[colName][1][1]\n",
    "\n",
    "            pr0 = numProb(std0, colVal, mean0)\n",
    "            lognP0 = math.log(pr0, 10)\n",
    "            \n",
    "            pr1 = numProb(std1, colVal, mean1)\n",
    "            lognP1 = math.log(pr1, 10)\n",
    "\n",
    "        elif colName in categorical: #{ <humidity>: [ {<low>: [p0, p1], <medium>: [p0, p1], <high>: [p0, p1]} ] }\n",
    "            pr_c0 = prob_ca[colName][0][colVal][0]\n",
    "            pr_c1 = prob_ca[colName][0][colVal][1]\n",
    "        \n",
    "            logcP0 = math.log(pr_c0,10)\n",
    "            \n",
    "            logcP1 = math.log(pr_c1,10)\n",
    "\n",
    "        likelihood_1 = likelihood_1 + lognP1 + logcP1\n",
    "        likelihood_0 = likelihood_0 + lognP0 + logcP0\n",
    "    \n",
    "\n",
    "    if likelihood_1 + math.log(p1,10) >= likelihood_0 + math.log(p0,10):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748     0\n",
       "3802    0\n",
       "937     0\n",
       "1957    0\n",
       "1077    0\n",
       "548     0\n",
       "2720    0\n",
       "1108    0\n",
       "1344    0\n",
       "4089    1\n",
       "1959    0\n",
       "1212    1\n",
       "514     0\n",
       "3458    0\n",
       "560     0\n",
       "2884    0\n",
       "3197    1\n",
       "268     0\n",
       "4142    0\n",
       "2812    0\n",
       "4205    0\n",
       "269     0\n",
       "3207    0\n",
       "2816    0\n",
       "814     0\n",
       "1186    1\n",
       "3246    0\n",
       "3247    0\n",
       "4051    0\n",
       "455     0\n",
       "       ..\n",
       "302     1\n",
       "282     0\n",
       "4307    1\n",
       "373     0\n",
       "4271    1\n",
       "4291    0\n",
       "2566    0\n",
       "3901    0\n",
       "1268    0\n",
       "1459    0\n",
       "579     0\n",
       "4437    0\n",
       "1551    0\n",
       "360     0\n",
       "4423    0\n",
       "3179    1\n",
       "1305    0\n",
       "4138    0\n",
       "2481    1\n",
       "2164    0\n",
       "1590    0\n",
       "2001    0\n",
       "4239    0\n",
       "4055    1\n",
       "4352    0\n",
       "4410    0\n",
       "3976    0\n",
       "1575    0\n",
       "3150    0\n",
       "415     0\n",
       "Name: prediction, Length: 900, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def helper(df, predict_col):\n",
    "    df[predict_col] = df.apply(predict, axis=1, args=(0))    \n",
    "    \n",
    "    return df[predict_col]\n",
    "helper(validate,'prediction')\n",
    "# print validate['validate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds measures for tp, fp, tn, fn , accuracy,precision, recall\n",
    "def findMeasures(df, predict_col):\n",
    "    truePos=0\n",
    "    trueNeg=0\n",
    "    falsePos=0\n",
    "    falseNeg=0\n",
    "    \n",
    "#     for index, row in validate.iterrows():\n",
    "    for index, row in df.iterrows():\n",
    "    \n",
    "        \n",
    "        if row[predict_col]==0 and row[target]==0:\n",
    "            trueNeg += 1\n",
    "            \n",
    "            \n",
    "        elif row[predict_col]==0 and row[target]==1:\n",
    "    \n",
    "            falseNeg += 1\n",
    "    \n",
    "        elif row[predict_col]==1 and row[target]==1:\n",
    "           \n",
    "            truePos += 1\n",
    "           \n",
    "        \n",
    "        elif row[predict_col]==1 and row[target]==0:\n",
    "            falsePos += 1\n",
    "\n",
    "    sumtotal = truePos + trueNeg + falsePos + falseNeg\n",
    "    accuracy = ((float)(truePos + trueNeg))/sumtotal\n",
    "    precision = ((float)(truePos))/(truePos + falsePos)\n",
    "    recall = ((float)(truePos))/(truePos + falseNeg)\n",
    "    try:\n",
    "        f1_score_den = 1.0/recall + 1.0/precision\n",
    "        f1_score = 2.0/f1_score_den\n",
    "    except:\n",
    "        f1_score=0\n",
    "    print \"TP, TN, FP, FN: \", truePos, trueNeg, falsePos, falseNeg\n",
    "    print \"A, P, R, F: \",accuracy*100, precision*100, recall*100, f1_score\n",
    "    return accuracy*100, precision*100, recall*100, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, TN, FP, FN:  56 745 55 44\n",
      "A, P, R, F:  89.0 50.4504504505 56.0 0.530805687204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89.0, 50.45045045045045, 56.00000000000001, 0.5308056872037914)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMeasures(validate, 'prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file for testing: /home/shruti/Documents/pg2k18/sem2/smai/A1/A2/test_loan.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    1\n",
       "9    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = raw_input(\"Enter file for testing: \")\n",
    "test = pd.read_csv(filename, header = None)\n",
    "test.columns = ['id', 'age', 'exp', 'income', 'zip', 'fam_size', 'spending', 'education', 'mortgage', 'securities_account', 'certi_dep', 'net_banking', 'UniversalBank_cc']\n",
    "numerical = ['age', 'exp', 'income', 'fam_size', 'spending', 'mortgage']\n",
    "categorical = ['education', 'securities_account', 'certi_dep', 'net_banking', 'UniversalBank_cc']\n",
    "test = test.drop(test.index[0])\n",
    "helper(test,'label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
