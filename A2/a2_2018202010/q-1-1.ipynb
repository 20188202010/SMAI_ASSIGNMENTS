{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math #sqrt\n",
    "import sys #max\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise dataframe\n",
    "def normalise(df, cols):\n",
    "    for c in cols:\n",
    "        maxi = df[c].max()\n",
    "        mini = df[c].min()\n",
    "        diff = maxi - mini\n",
    "        df[c] = (df[c] - mini)/diff\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findKnn parameters:\n",
    "- row: one row of validation\n",
    "- df_t: training dataset\n",
    "- cols: numerical attribute list\n",
    "- target: which class the attribute belongs to, eg class for robot, species for iris\n",
    "- label: unique identifier for attribute\n",
    "- findNeigh: k neighbour finder fn\n",
    "- distanceMeasure: which distance is to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKnn(row, df_t, cols, target, findNeigh, distanceMeasure, k, default=0):\n",
    "    listOfList=[]\n",
    "    \n",
    "    #iterate on each row of training set.\n",
    "    for i, r in df_t.iterrows():\n",
    "        temp = distanceMeasure(row,r,cols,target) #temp: [ <distance>, <class>]\n",
    "        listOfList.append(temp)\n",
    "    \n",
    "    listOfList.sort()\n",
    "#     print \"lol: \",listOfList\n",
    "    pred = findNeigh(listOfList, k)\n",
    "\n",
    "#     print \"pred: \", pred, \"actual: \", row[target]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def helper_knn(df, df_t, predict_col, cols, target, findNeigh, distanceMeasure, k):\n",
    "    df[predict_col] = df.apply(findKnn, axis=1, args=(df_t, cols, target, findNeigh, distanceMeasure, k, 0))\n",
    "    return df[predict_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Report precision, recall, f1 score and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns Confusion Matrix\n",
    "def createCM(predicted, actual):\n",
    "    pred = pd.Series(predicted, name='Predicted')\n",
    "    actu = pd.Series(actual,    name='Actual')\n",
    "    conf = pd.crosstab(actu, pred)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find accuracy, precision, recall\n",
    "#parameter: confusion matrix\n",
    "def findMeasures(mat):\n",
    "    \n",
    "    diag = 0\n",
    "    tot = 0\n",
    "    for i in mat:\n",
    "        diag += mat[i][i]\n",
    "        tot += mat[i].sum()\n",
    "    accuracy = float(diag)/tot\n",
    "    \n",
    "    \n",
    "    precision = np.diag(mat) / np.sum(mat, axis = 0)\n",
    "    recall = np.diag(mat) / np.sum(mat, axis = 1)\n",
    "    f1_score_den = 1/precision + 1/recall\n",
    "    f1_score = float(2)/f1_score_den\n",
    "    return accuracy, precision, recall,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllK(df, df_t, cols, target, predict_col_name, funNeigh, funDistance):\n",
    "    n = math.sqrt( len(df_t) ) + 1 #k is less than equal to root n\n",
    "\n",
    "    length = int(n)\n",
    "\n",
    "    all_predictions = []\n",
    "    max_acc = -sys.maxint - 1\n",
    "    actual = df[target]\n",
    "    x_axis = range(1, length,2)\n",
    "    print \"x: \", x_axis,\n",
    "    for i in x_axis:\n",
    "\n",
    "        predict_col = predict_col_name + str(i) #eg for r1, v_robo_<1>\n",
    "#         print \"K: \",i\n",
    "        helper_knn(df, df_t, predict_col, cols, target, funNeigh, funDistance, i)\n",
    "        all_predictions.append(df[predict_col])\n",
    "    \n",
    "    y_axis = []\n",
    "    count = 1\n",
    "    max_k = 0\n",
    "    for one_prediction in all_predictions:\n",
    "        confusion_matrix = createCM(one_prediction, actual)\n",
    "        accuracy = findMeasures(confusion_matrix)[0]\n",
    "        if accuracy > max_acc:\n",
    "            max_acc = accuracy\n",
    "            max_k = count\n",
    "        y_axis.append(accuracy)\n",
    "        if 'iris' in predict_col_name:\n",
    "            count += 2\n",
    "        elif 'robo' in predict_col_name:\n",
    "            count += 1\n",
    "    print \"y: \",y_axis, \"maxK: \",max_k\n",
    "    return x_axis, y_axis, max_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraphs(x1, y1, x2, y2, x3, y3,part):\n",
    "    fig, axes = plt.subplots(figsize=(7, 7))\n",
    "    axes.plot(x1, y1, label=\"euclidean distance\")\n",
    "    axes.plot(x2, y2, label=\"manhattan distance\")\n",
    "    axes.plot(x3, y3, label=\"chebyshev distance\")\n",
    "    axes.grid(True)\n",
    "    \n",
    "    axes.set_xlabel('k')\n",
    "    axes.set_ylabel('Accuracy %')\n",
    "    axes.legend(loc='best')\n",
    "    name = part+str(runs)+'.png'\n",
    "    axes.set_title('k vs Accuracy')\n",
    "    fig.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeAnalysis(df_v, df_t, predict_col, num_col, target, funNeigh, funDist, bestK):\n",
    "    df_v[predict_col] = helper_knn(df_v, df_t, predict_col, num_col, target, funNeigh, funDist, bestK)\n",
    "    predicted_val = df_v[predict_col]\n",
    "    actual_val = df_v[target]\n",
    "    confusion_mat = createCM(predicted_val, actual_val)\n",
    "    print \"Confusion Matrix:\"\n",
    "    print confusion_mat\n",
    "    a,p,r,f = findMeasures(confusion_mat)\n",
    "    print \"Accuracy: \",a*100, \"\\nPrecision: \", p*100,\"\\nRecall:\", r*100,\"\\nF1Score: \",f\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different distance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEuclidean(unknown_class, known_class ,cols, target):\n",
    "    sum_of_squares = 0\n",
    "    class_dist = []\n",
    "    for i in cols:\n",
    "        xi = (unknown_class[i] - known_class[i])**2\n",
    "        sum_of_squares += xi\n",
    "    \n",
    "    dist = math.sqrt(sum_of_squares)\n",
    "    class_dist = [dist, known_class[target]]\n",
    "    return class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findChebyshev(unknown_class, known_class ,cols, target):\n",
    "    class_dist = []\n",
    "    maxi = -sys.maxint - 1\n",
    "    for i in cols:\n",
    "        xi = abs(unknown_class[i] - known_class[i])\n",
    "        if maxi < xi:\n",
    "            maxi = xi\n",
    "    class_dist = [maxi, known_class[target]]\n",
    "    return class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findManhattan(unknown_class, known_class ,cols, target):\n",
    "    dist = 0\n",
    "    class_dist = []\n",
    "    for i in cols:\n",
    "        xi = abs(unknown_class[i] - known_class[i])\n",
    "        dist += xi\n",
    "    \n",
    "    class_dist = [dist, known_class[target]]\n",
    "    return class_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SciKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareScikit(df,target,identifier=None):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    if identifier is not None:\n",
    "        df[identifier] = le.fit_transform(df[identifier])\n",
    "    # dataset_R1=dataset_R1.drop('index',1)\n",
    "    if identifier is not None:\n",
    "        cols = [col for col in df.columns if col not in [target,identifier]]\n",
    "    else:\n",
    "        cols = [col for col in df.columns if col not in [target]]\n",
    "    data = df[cols]\n",
    "    target = df[target]\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data,target, test_size = 0.20, random_state = 10)\n",
    "\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(data_train)\n",
    "\n",
    "    data_train = scaler.transform(data_train)  \n",
    "    data_test = scaler.transform(data_test)  \n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "    classifier.fit(data_train, target_train) \n",
    "    y_pred = classifier.predict(data_test) \n",
    "    error = []\n",
    "\n",
    "    for i in range(1, int(math.sqrt(len(data_train)))):  \n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(data_train, target_train)\n",
    "        pred_i = knn.predict(data_test)\n",
    "        error.append(np.mean(pred_i != target_test))\n",
    "#     plt.figure(figsize=(7, 7))  \n",
    "#     plt.plot(range(1, int(math.sqrt(len(data_train)))), error, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
    "#     plt.title('Error Rate K Value')  \n",
    "#     plt.xlabel('K Value')  \n",
    "#     plt.ylabel('Mean Error')\n",
    "    score = accuracy_score(target_test, y_pred)\n",
    "    print \"score\",score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-1: Robot1 & Robot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_num = ['a1', 'a2', 'a3', 'a4', 'a5', 'a6'] #numerical attr for robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findKNeighbours(class_dist, k) function returns label of unknown class based on k nearest neighbours\n",
    "- class_dist: list of list. Each sublist has distance and corresponding class labe\n",
    "- k: value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKNeighbours(class_dist, k):\n",
    "    #slice first K elements\n",
    "    topK = class_dist[0:k]\n",
    "\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    \n",
    "    #traverse the second list and count no of 1,0\n",
    "    for i in topK:\n",
    "        if i[1] == 0:\n",
    "            count0 += 1\n",
    "        elif i[1] == 1:\n",
    "            count1 += 1\n",
    "    if count0 > count1:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROBOT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 483, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 467, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python2.7/posixpath.py\", line 364, in abspath\n",
      "    cwd = os.getcwd()\n",
      "OSError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "dataset_R1 = pd.read_csv(\"./RobotDataset/Robot1\", header = None, delim_whitespace=True)\n",
    "dataset_R1.columns = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'Id']\n",
    "dataset_R1 = dataset_R1.sample(frac=1)\n",
    "dataset_R1 = normalise(dataset_R1, robot_num)\n",
    "train_R1, validate_R1 = np.split(dataset_R1, [int(.8*len(dataset_R1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test file Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dR1 =raw_input(\"Enter test file for Robot 1: \")\n",
    "test_dR1 = pd.read_csv(test_dR1, header = None, delim_whitespace=True)\n",
    "test_dR1.columns = ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'Id']\n",
    "test_dR1 = normalise(test_dR1, robot_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Finds accuracy for all values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"EUCLIDEAN:\"\n",
    "xe,ye,ke = findAllK(validate_R1, train_R1, robot_num, 'class', 'v_robo_', findKNeighbours, findEuclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"MANHATTAN:\"\n",
    "xm,ym,km = findAllK(validate_R1, train_R1, robot_num, 'class', 'v_robo_', findKNeighbours, findManhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"CHEBYSHEV:\"\n",
    "xc,yc,kc = findAllK(validate_R1, train_R1, robot_num, 'class', 'v_robo_', findKNeighbours, findChebyshev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGraphs(xe, ye, xm, ym, xc, yc, 'robot1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1 Score for best value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Euclidean\", ke\n",
    "completeAnalysis(validate_R1, train_R1, 'validate_R1',robot_num, 'class', findKNeighbours, findEuclidean, ke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Manhattan\", km\n",
    "completeAnalysis(validate_R1, train_R1, 'validate_R1',robot_num, 'class', findKNeighbours, findManhattan, km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Chebyshev\", kc\n",
    "completeAnalysis(validate_R1, train_R1, 'validate_R1',robot_num, 'class', findKNeighbours, findChebyshev, kc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_knn(test_dR1, train_R1, 'robot1_test', robot_num, 'class', findKNeighbours, findEuclidean, ke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareScikit(dataset_R1, 'class', 'Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROBOT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_R2 = pd.read_csv(\"RobotDataset/Robot2\", header = None, delim_whitespace=True)\n",
    "dataset_R2.columns = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'Id']\n",
    "dataset_R2 = dataset_R2.sample(frac=1)\n",
    "dataset_R2 = normalise(dataset_R2, robot_num)\n",
    "train_R2, validate_R2 = np.split(dataset_R2, [int(.8*len(dataset_R2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dR2 = raw_input(\"Enter test file for Robot 2: \")\n",
    "test_dR2 = pd.read_csv(test_dR2, header = None, delim_whitespace=True)\n",
    "test_dR2.columns = ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'Id']\n",
    "test_dR2 = normalise(test_dR2, robot_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Finds accuracy for all values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"EUCLIDEAN\"\n",
    "xe2,ye2,ke2 = findAllK(validate_R2, train_R2, robot_num, 'class', 'v_robo2_', findKNeighbours, findEuclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"MANHATTAN\"\n",
    "xm2,ym2,km2 = findAllK(validate_R2, train_R2, robot_num, 'class', 'v_robo2_', findKNeighbours, findManhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"CHEBYSHEV\"\n",
    "xc2,yc2,kc2 = findAllK(validate_R2, train_R2, robot_num, 'class', 'v_robo2_', findKNeighbours, findChebyshev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGraphs(xe2, ye2, xm2, ym2, xc2, yc2,'robot2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1 Score for best value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Euclidean\"\n",
    "completeAnalysis(validate_R2, train_R2, 'validate_R2',robot_num, 'class', findKNeighbours, findEuclidean, ke2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Manhattan\"\n",
    "completeAnalysis(validate_R2, train_R2, 'validate_R2',robot_num, 'class',  findKNeighbours, findManhattan, km2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Chebyshev\"\n",
    "completeAnalysis(validate_R2, train_R2, 'validate_R2',robot_num, 'class',  findKNeighbours, findChebyshev, kc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_knn(test_dR2, train_R2, 'robot2_test', robot_num, 'class',  findKNeighbours, findEuclidean, ke2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareScikit(dataset_R2, 'class', 'Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Iris.csv The data set consists of samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris = pd.read_csv(\"Iris/Iris.csv\", header=None)\n",
    "dataset_iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_num = ['sepal_length', 'sepal_width','petal_length', 'petal_width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris = dataset_iris.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris = normalise(dataset_iris, iris_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iris, validate_iris = np.split(dataset_iris, [int(.8*len(dataset_iris))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iris = raw_input(\"Enter test file for Iris: \")\n",
    "test_iris = pd.read_csv(test_iris, header = None)\n",
    "test_iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "test_iris = normalise(test_iris, iris_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findKNeighboursIris(class_dist, k) function returns label of unknown class based on k nearest neighbours\n",
    "- class_dist: list of list. Each sublist has distance and corresponding class labe\n",
    "- k: value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKNeighboursIris(class_dist, k):\n",
    "    #slice first K elements\n",
    "    topK = class_dist[0:k]\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    #traverse the second list and count no of 1,0\n",
    "    for i in topK:\n",
    "        if i[1] == 'Iris-setosa':\n",
    "            count0 += 1\n",
    "        elif i[1] == 'Iris-virginica':            \n",
    "            count1 += 1\n",
    "        elif i[1] == 'Iris-versicolor':          \n",
    "            count2 += 1\n",
    "    \n",
    "    if (count0 >= count1) and (count0 >= count2): \n",
    "        label = 'Iris-setosa'\n",
    "  \n",
    "    elif (count1 >= count0) and (count1 >= count2): \n",
    "        label = 'Iris-virginica'\n",
    "    else: \n",
    "        label = 'Iris-versicolor' \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find accuracy for all values of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Euclidean:\"\n",
    "xei,yei,kei = findAllK(validate_iris, train_iris, iris_num, 'species',  'v_iris_',findKNeighboursIris, findEuclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Manhattan\"\n",
    "xmi,ymi,kmi = findAllK(validate_iris, train_iris, iris_num, 'species',  'v_iris_',findKNeighboursIris, findManhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Chebyshev\"\n",
    "xci,yci,kci = findAllK(validate_iris, train_iris, iris_num, 'species', 'v_iris_',findKNeighboursIris, findChebyshev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGraphs(xei,yei, xmi,ymi, xci, yci,'iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1 Score for best value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Euclidean\"\n",
    "completeAnalysis(validate_iris, train_iris, 'validate_iris',iris_num, 'species', findKNeighboursIris, findEuclidean, kei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Manhattan\"\n",
    "completeAnalysis(validate_iris, train_iris, 'validate_iris',iris_num, 'species', findKNeighboursIris, findManhattan, kmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Chebyshev\"\n",
    "completeAnalysis(validate_iris, train_iris, 'validate_iris',iris_num, 'species', findKNeighboursIris, findChebyshev, kci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_knn(test_iris, train_iris, 'iris_test', iris_num, 'species',findKNeighboursIris, findEuclidean, kei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareScikit(dataset_iris, 'species',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible Reasons for Better Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no training phase included in KNN classifier. So it performs faster than other classifiers. This is also effective when training data is large\n",
    "No assumptions are made about the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
