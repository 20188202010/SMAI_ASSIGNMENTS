{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Use  the  Admission dataset to perform the following task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare  the  performances  of  logistic  regression  model  withKNN model on the Admission dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  450 9\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../input_data/AdmissionDataset/data.csv\")\n",
    "df_r, df_c = dataset.shape #without drop\n",
    "print \"Dataset: \", df_r, df_c\n",
    "target = 'Chance of Admit '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Serial No.'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GRE Score  TOEFL Score  University Rating       SOP      LOR       CGPA  \\\n",
      "0   0.040384    -0.690991          -0.988084 -0.866855 -1.597605 -0.713316   \n",
      "1   0.216817     0.139084          -0.111086 -0.363520  0.033837 -0.062724   \n",
      "2   0.481468     0.471114          -0.111086  0.139815 -1.053791  0.154140   \n",
      "3   0.834335     0.969158           1.642909  1.146486  0.577651  1.371916   \n",
      "4   0.216817    -0.192946          -0.111086  0.139815 -1.053791 -0.413043   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0 -1.111779              0.65  \n",
      "1  0.897460              0.71  \n",
      "2  0.897460              0.80  \n",
      "3  0.897460              0.91  \n",
      "4  0.897460              0.74  \n"
     ]
    }
   ],
   "source": [
    "#normalise dataframe\n",
    "def normalise(df):\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        if c != target:\n",
    "            sd = df[c].std()\n",
    "            mean = df[c].mean()\n",
    "            df[c] = (df[c] - mean)/sd\n",
    "    return df\n",
    "dataset = normalise(dataset)\n",
    "# print dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds classes from chance of admit for ENTIRE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClasses(row, threshold, default=0):\n",
    "    if row[target] <= threshold:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GRE Score  TOEFL Score  University Rating       SOP      LOR       CGPA  \\\n",
      "0   0.040384    -0.690991          -0.988084 -0.866855 -1.597605 -0.713316   \n",
      "1   0.216817     0.139084          -0.111086 -0.363520  0.033837 -0.062724   \n",
      "2   0.481468     0.471114          -0.111086  0.139815 -1.053791  0.154140   \n",
      "3   0.834335     0.969158           1.642909  1.146486  0.577651  1.371916   \n",
      "4   0.216817    -0.192946          -0.111086  0.139815 -1.053791 -0.413043   \n",
      "\n",
      "   Research  Chance of Admit   class  \n",
      "0 -1.111779              0.65      1  \n",
      "1  0.897460              0.71      1  \n",
      "2  0.897460              0.80      1  \n",
      "3  0.897460              0.91      1  \n",
      "4  0.897460              0.74      1  \n"
     ]
    }
   ],
   "source": [
    "def helper_classes(df, predicted_class):\n",
    "    threshold = 0.5\n",
    "    df[predicted_class] = df.apply(findClasses, axis=1, args=(threshold,0,))\n",
    "    return df[predicted_class]\n",
    "dataset['class'] = helper_classes(dataset, 'class')\n",
    "# print dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 9\n",
      "     GRE Score  TOEFL Score  University Rating       SOP      LOR       CGPA  \\\n",
      "360  -0.930001    -1.189036          -0.988084 -0.363520 -0.509977 -0.963544   \n",
      "361  -1.900387    -1.853096          -0.988084 -1.873525 -1.597605 -2.064546   \n",
      "362  -0.841785    -0.358961          -0.988084 -1.370190  0.033837 -0.796725   \n",
      "363  -0.224267    -0.358961          -0.988084 -0.866855 -1.597605 -1.564091   \n",
      "364   0.216817     0.803143          -0.111086 -0.866855 -1.597605  0.220868   \n",
      "\n",
      "     Research  Chance of Admit   class  \n",
      "360 -1.111779              0.48      0  \n",
      "361 -1.111779              0.47      0  \n",
      "362 -1.111779              0.53      1  \n",
      "363 -1.111779              0.70      1  \n",
      "364  0.897460              0.78      1  \n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.sample(frac=1)\n",
    "train, validate = np.split(dataset, [int(.8*len(dataset))])\n",
    "train_rows, train_cols = train.shape\n",
    "print train_rows, train_cols\n",
    "# print validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEuclidean(unknown_class, known_class):\n",
    "\n",
    "    cols = ['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research']\n",
    "    sum_of_squares = 0\n",
    "    class_dist = []\n",
    "    for i in cols:\n",
    "        if i != target:\n",
    "            xi = (unknown_class[i] - known_class[i])**2\n",
    "            sum_of_squares += xi\n",
    "    \n",
    "    dist = math.sqrt(sum_of_squares)\n",
    "    class_dist = [dist, known_class['class']]\n",
    "\n",
    "    return class_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKNeighbours(class_dist, k):\n",
    "    \n",
    "    topK = class_dist[0:k]\n",
    "\n",
    "    count0 = 0\n",
    "    count1 = 0   \n",
    "    #traverse the second list and count no of 1,0\n",
    "    for i in topK:\n",
    "        if i[1] == 0:\n",
    "            count0 += 1\n",
    "        elif i[1] == 1:\n",
    "            count1 += 1\n",
    "    if count0 > count1:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "#     print \"label: \",label\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     GRE Score  TOEFL Score  University Rating       SOP      LOR       CGPA  \\\n",
      "360  -0.930001    -1.189036          -0.988084 -0.363520 -0.509977 -0.963544   \n",
      "361  -1.900387    -1.853096          -0.988084 -1.873525 -1.597605 -2.064546   \n",
      "362  -0.841785    -0.358961          -0.988084 -1.370190  0.033837 -0.796725   \n",
      "363  -0.224267    -0.358961          -0.988084 -0.866855 -1.597605 -1.564091   \n",
      "364   0.216817     0.803143          -0.111086 -0.866855 -1.597605  0.220868   \n",
      "\n",
      "     Research  Chance of Admit   class  predict_col  \n",
      "360 -1.111779              0.48      0            1  \n",
      "361 -1.111779              0.47      0            0  \n",
      "362 -1.111779              0.53      1            1  \n",
      "363 -1.111779              0.70      1            1  \n",
      "364  0.897460              0.78      1            1  \n"
     ]
    }
   ],
   "source": [
    "def findKnn(row, df_t, findNeigh, distanceMeasure, k, default=0):\n",
    "    listOfList=[]\n",
    "\n",
    "    #iterate on each row of training set.\n",
    "    for i, r in df_t.iterrows():\n",
    "        \n",
    "        temp = distanceMeasure(row,r) #temp: [ <distance>, <class>]\n",
    "        listOfList.append(temp)    \n",
    "    listOfList.sort()\n",
    "\n",
    "    pred = findNeigh(listOfList, k)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def helper_knn(df, df_t, predict_col, findNeigh, distanceMeasure, k):\n",
    "    df[predict_col] = df.apply(findKnn, axis=1, args=(df_t, findNeigh, distanceMeasure, k, 0))\n",
    "    return df[predict_col]\n",
    "validate['predict_col'] = helper_knn(validate, train, 'predict_col', findKNeighbours, findEuclidean, 3)\n",
    "# print validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns Confusion Matrix\n",
    "def createCM(predicted, actual):\n",
    "\n",
    "    pred = pd.Series(predicted, name='Predicted')\n",
    "\n",
    "    actu = pd.Series(actual,    name='Actual')\n",
    "\n",
    "    conf = pd.crosstab(actu, pred)\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find accuracy, precision, recall\n",
    "#parameter: confusion matrix\n",
    "def findMeasures(mat):    \n",
    "    diag = 0\n",
    "    tot = 0\n",
    "    for i in mat:\n",
    "        diag += mat[i][i]\n",
    "        tot += mat[i].sum()\n",
    "    accuracy = float(diag)/tot\n",
    "\n",
    "    precision = np.diag(mat) / np.sum(mat, axis = 0)\n",
    "    recall = np.diag(mat) / np.sum(mat, axis = 1)\n",
    "    f1_score_den = 1/precision + 1/recall\n",
    "    f1_score = float(2)/f1_score_den\n",
    "    return accuracy, precision, recall,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeAnalysis(df_v, df_t, predict_col, funNeigh, funDist, bestK):\n",
    "    df_v[predict_col] = helper_knn(df_v, df_t, predict_col, funNeigh, funDist, bestK)\n",
    "    \n",
    "    predicted_val = df_v[predict_col]\n",
    "    print \"predicted: \",len(predicted_val)\n",
    "    \n",
    "    actual_val = df_v[target]\n",
    "    print \"actual val: \", len(actual_val)\n",
    "    mean_actual = actual_val.mean()\n",
    "    \n",
    "\n",
    "    \n",
    "    class_actual = df_v['class']\n",
    "    confusion_mat = createCM(predicted_val, class_actual)\n",
    "    print \"Confusion Matrix:\"\n",
    "    print confusion_mat\n",
    "    a,p,r,f = findMeasures(confusion_mat)\n",
    "    print \"Accuracy: \",a*100, \"\\nPrecision: \", p*100,\"\\nRecall:\", r*100,\"\\nF1Score: \",f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  90\n",
      "actual val:  90\n",
      "Confusion Matrix:\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          4   5\n",
      "1          0  81\n",
      "Accuracy:  94.44444444444444 \n",
      "Precision:  Predicted\n",
      "0    100.000000\n",
      "1     94.186047\n",
      "dtype: float64 \n",
      "Recall: Actual\n",
      "0     44.444444\n",
      "1    100.000000\n",
      "dtype: float64 \n",
      "F1Score:  Predicted\n",
      "0    0.615385\n",
      "1    0.970060\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "completeAnalysis(validate, train, 'validate', findKNeighbours, findEuclidean, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
