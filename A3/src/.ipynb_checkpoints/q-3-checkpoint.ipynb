{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Implement logistic regression using One vs All and One vs One approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../input_data/WineQuality/data.csv\", sep = \";\")\n",
    "target = 'quality'\n",
    "new_target = dataset[target]\n",
    "# print dataset.head()\n",
    "col_list = dataset.columns[:-1]\n",
    "df_c = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise dataframe\n",
    "def standardise(df):\n",
    "    global target\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        if c != target:\n",
    "            sd = df[c].std()\n",
    "            mean = df[c].mean()\n",
    "            \n",
    "            df[c] = (df[c] - mean)/sd\n",
    "    return df\n",
    "\n",
    "dataset = standardise(dataset)\n",
    "# print dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = np.split(dataset, [int(.8*len(dataset))])\n",
    "train_row, train_col = train.shape\n",
    "print \"TRAIN: \", train.shape\n",
    "print \"Validate: \", validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init 12 theta b0,b1...b11\n",
    "def initTheta(n):\n",
    "    theta = np.zeros(n - 1 + 1) #remove chance of admit, serial no. add 1 b0 col\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeX(df):\n",
    "    if target in df.columns:\n",
    "        df = df.drop([target], axis=1)\n",
    "    X = df.values\n",
    "    X = np.insert(X, 0, values=1, axis=1)\n",
    "    return X\n",
    "\n",
    "matrix = makeX(train)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE VS ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(mat, actual, eta, length = None):\n",
    "    mat_tr = mat.transpose()\n",
    "    ilist = []\n",
    "    clist = []\n",
    "    theta = initTheta(df_c) #df_c: no of columns in original dataframe\n",
    "    for i in range(0, 1000):\n",
    "        pred = np.dot(mat, theta)\n",
    "        loss = pred - actual\n",
    "        if length is None:\n",
    "            cost = np.sum((loss)**2) / (2 * train_row)\n",
    "        else:\n",
    "            cost = np.sum((loss)**2) / (2 * length)\n",
    "            \n",
    "        ilist.append(i)\n",
    "        clist.append(cost)\n",
    "        if length is None:\n",
    "            gradient = np.dot(mat_tr, loss) / train_row\n",
    "        else:\n",
    "            gradient = np.dot(mat_tr, loss) / length\n",
    "            \n",
    "        theta = theta - eta * gradient\n",
    "    return theta, ilist, clist\n",
    "theta, iterations, cost = gradientDescent(matrix, train[target], 0.001)\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNewActual(df, val):\n",
    "    new_y_actual = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['quality'] == val:\n",
    "            new_y_actual.append(1)\n",
    "        else:\n",
    "            new_y_actual.append(0)\n",
    "    return new_y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_m = makeX(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedDF = pd.DataFrame()\n",
    "print predictedDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_mat, target_col, alpha, toBePredicted): \n",
    "    unique = target_col.unique()\n",
    "   \n",
    "    for u in unique:\n",
    "        new_actual = findNewActual(train, u)\n",
    "        reqd_theta, reqd_ilist, reqd_clist = gradientDescent(train_mat, new_actual, alpha)\n",
    "        y_matrix = np.dot(toBePredicted, reqd_theta)\n",
    "        predict = 1.0 / (1 + np.exp(-y_matrix)) #sigmoid function\n",
    "\n",
    "        title = str(u)\n",
    "        predictedDF[title] = predict\n",
    "    class_predict = predictedDF.idxmax(axis = 1)\n",
    "\n",
    "    return class_predict\n",
    "\n",
    "y_predict_series = predict(matrix, train[target], 0.1, validate_m)\n",
    "y_predict = y_predict_series.astype(int)\n",
    "\n",
    "def actualClasses(validate):\n",
    "    target_col = validate[target]\n",
    "    target_m = target_col.values\n",
    "    return target_m\n",
    "y_actual = actualClasses(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_actual, y_predict) \n",
    "print 'Confusion Matrix :'\n",
    "print(results) \n",
    "print 'Accuracy Score :'\n",
    "print accuracy_score(y_actual, y_predict)\n",
    "print 'Precision Score :'\n",
    "print precision_score(y_actual, y_predict, average=None).tolist()\n",
    "print 'Recall Score :'\n",
    "print recall_score(y_actual, y_predict, average=None).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print predictedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE VS ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOne(train_mat, target_col, alpha, toBePredicted): \n",
    "    rows = toBePredicted.shape[0]\n",
    "    prob_row = np.zeros(shape=(rows,11))\n",
    "    #   class    0 1 2 3 4 5 6 7 8 9 10 \n",
    "    #  rowno. 0[ [ c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10 ] \n",
    "    #         1  [ c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10 ] \n",
    "    #         :\n",
    "    #      rows  [ c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10 ] ]\n",
    "    cnt = 0\n",
    "    \n",
    "    #runs for nC2 combinations\n",
    "    for i in range(0,10):\n",
    "        for j in range(i+1, 11):\n",
    "\n",
    "            any_two = train[(train.quality == i) | (train.quality == j)]\n",
    "\n",
    "            if len(any_two['quality'].unique()) != 2:\n",
    "                continue\n",
    "            else:\n",
    "                any_matrix = makeX(any_two)\n",
    "                y_actual_temp = findNewActual(any_two, i)\n",
    "                len_matrix = any_matrix.shape[0]\n",
    "                reqd_theta, reqd_ilist, reqd_clist = gradientDescent(any_matrix, y_actual_temp, alpha, len_matrix)\n",
    "                y_matrix = np.dot(toBePredicted, reqd_theta)\n",
    "                predict = 1.0 / (1 + np.exp(-y_matrix)) #sigmoid function\n",
    "\n",
    "                class_predict = []\n",
    "                for p in predict:\n",
    "                    if p >= 0.6:\n",
    "                        class_predict.append(i)\n",
    "                    else: \n",
    "                        class_predict.append(j)\n",
    "                cnt+=1\n",
    "\n",
    "                for r in range(rows):\n",
    "                    this_class = class_predict[r]\n",
    "                    prob_row[r][this_class] += 1\n",
    "\n",
    "\n",
    "    lis = []\n",
    "\n",
    "    \n",
    "    for r in range(rows):\n",
    "        max_vote = prob_row[r].argmax()\n",
    "        lis.append(max_vote)\n",
    "\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict = predictOne(matrix, train[target], 0.1, validate_m)\n",
    "print \"Confusion Matrix: \"\n",
    "results = confusion_matrix(y_actual, y_predict) \n",
    "print 'Accuracy Score :'\n",
    "print accuracy_score(y_actual, y_predict)\n",
    "print 'Precision Score :'\n",
    "print precision_score(y_actual, y_predict, average=None).tolist()\n",
    "print 'Recall Score :'\n",
    "print recall_score(y_actual, y_predict, average=None).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
