{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "Analyse how the hyper-parameter Î» plays a role in deciding between bias and variance.\n",
    "\n",
    "*Sol*: \n",
    "- A higher value of $\\lambda $ means smaller coefficients of the model. This results in much simpler model\n",
    "- When $\\lambda $ reaches values close to infinity, underfitting takes place. \n",
    "- This means bias increases with increase in $\\lambda $.\n",
    "- With increase in $\\lambda $ model generalizes in a better way, hence decreasing variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 4\n",
    "Analyse how the two different regularisation techniques affect regression weights in terms of their values and what are the differences between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using $\\alpha$ = 0.001, number of iterations = 1000 and $\\lambda$ in the range of 0.1 to 50 with steps of 0.5.\n",
    "- We plot values of different beta coefficients with the corresponding $\\lambda$. \n",
    "<p> \n",
    "- In case of Ridge Regression, weights appear to vary linearly with little variation.\n",
    "- The formula used to update weights is: $\\theta_j := \\theta_j - \\alpha.1/m \\Sigma (h_\\theta (x ^ {(i)} ) - y ^{(i)} ) x_j ^ {(i)} - \\alpha *\\lambda *w_j /m$ </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"input_data/ridge.png\" height = 600 width = 800> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In case of Lasso Regression, weights drop drastically to 0\n",
    "- The formula used to update weights is: $\\theta_j := \\theta_j - \\alpha.1/m \\Sigma (h_\\theta (x ^ {(i)} ) - y ^{(i)} ) x_j ^ {(i)} - \\lambda .sgn(w_j) . 1/2m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"input_data/lasso.png\" height = 600 width = 800> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We observe that ridge regression decreases the coefficients in  a linear manner. In Lasso, weights converge to 0 more faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
