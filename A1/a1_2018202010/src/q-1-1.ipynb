{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1 Train decision tree only on categorical data.  Report precision,recall, f1 score and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys #for maxmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, root, pos, neg, tf):\n",
    "        self.root = root\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "        self.children = {}\n",
    "        self.isLeaf = tf\n",
    "        if(pos>neg):\n",
    "            self.result=1 #decision here\n",
    "        else:\n",
    "            self.result=0\n",
    "    def add_child(self, key, val):\n",
    "        self.children[key]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countYesNo(dataframe):\n",
    "#     left_col = dataframe['play']\n",
    "    left_col = dataframe['left']\n",
    "    pos = dataframe[left_col == 1] \n",
    "    \n",
    "    #no of rows of yes\n",
    "    yes_r, yes_c = pos.shape\n",
    "\n",
    "    neg = dataframe[left_col == 0]\n",
    "    \n",
    "    #no of rows of no\n",
    "    no_r, no_c = neg.shape\n",
    "    \n",
    "    return yes_r, no_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyCalculate(dataframe, col_name):\n",
    "    total_len=len(dataframe)\n",
    "    col=dataframe[col_name]\n",
    "    s = pd.Series(col)\n",
    "    count_arr=s.value_counts()\n",
    "#     print count_arr[0], count_arr[1]\n",
    "    entropy=0\n",
    "    for counts in count_arr:\n",
    "#         print counts\n",
    "        prob = float(counts)/total_len\n",
    "#         print prob\n",
    "        entropy += -1*prob* np.log2(prob)\n",
    "        \n",
    "#     print entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyAttribute(dataframe, col_name, label):\n",
    "    col=dataframe[col_name] \n",
    "    \n",
    "    #total rows in this col, eg sales -8990\n",
    "    col_len=len(col) \n",
    "#     print \"colLen: \",col_len\n",
    "    \n",
    "    #convert the column to series\n",
    "    s = pd.Series(col)\n",
    "    \n",
    "    #find all unique attr, eg low,med,high\n",
    "    unique_val = s.unique() \n",
    "#     print \"unique val: \",unique_val\n",
    "\n",
    "    total_entropy=0\n",
    "    \n",
    "    for i in unique_val:\n",
    "        #all rows in the col where sub attribute is i, eg for sales , i=accounting..\n",
    "        ar = dataframe[col==i]\n",
    "        \n",
    "        #find no. of rows for that subattribute\n",
    "        total_r, total_c = ar.shape\n",
    "#         print \"unique val, total r: \", i,total_r\n",
    "        \n",
    "        #made a dataframe for this attribute\n",
    "        cur_df = pd.DataFrame(ar) \n",
    "        \n",
    "        #now suppose attribute=sales, value=accounting, find entropy now for accounting\n",
    "        curr_entropy = entropyCalculate(cur_df, label)\n",
    "        \n",
    "#         print \"current entropy: \", curr_entropy\n",
    "        fraction = float(total_r)/col_len\n",
    "        total_entropy += fraction * curr_entropy\n",
    "        \n",
    "#         print \"total entropy: \", total_entropy\n",
    "    return total_entropy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxInfoGain(dataframe):\n",
    "    unique_cols = dataframe.columns.tolist()\n",
    "#     print \"unique cols: \",unique_cols\n",
    "#     label = 'play'\n",
    "    label = 'left'\n",
    "    \n",
    "    entropy = entropyCalculate(dataframe, label)\n",
    "#     print \"entropy: \",entropy\n",
    "    max = -sys.maxint - 1\n",
    "    root=''\n",
    "    for i in unique_cols:\n",
    "#         print \"col: \",i,\n",
    "        if i != label:            \n",
    "            attr_entropy = entropyAttribute(dataframe, i, label)\n",
    "            \n",
    "#             print \"attr entropy: \", attr_entropy\n",
    "            temp = entropy - attr_entropy\n",
    "#             print \"entropy: \",temp\n",
    "            if temp>max:\n",
    "                max=temp\n",
    "                root=i\n",
    "#     print \"root: \",root\n",
    "    return root, max        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(dataframe):\n",
    "    yes, no = countYesNo(dataframe)\n",
    "    \n",
    "#     percent = (yes/no)*100\n",
    "    \n",
    "    if no==0: #node is yes->1\n",
    "        return Node(1,yes,0,True)\n",
    "        \n",
    "    elif yes==0: #node is no->0\n",
    "        return Node(0,0,no,True)\n",
    "    \n",
    "    if len(dataframe.keys())==1: \n",
    "        if yes<no:\n",
    "            return Node(0,yes,no,True)\n",
    "        else:\n",
    "            return Node(1,yes,no,True)\n",
    "    \n",
    "    root_node, gain = findMaxInfoGain(dataframe) #work_acc\n",
    "    \n",
    "    tree_root = Node(root_node, yes, no, False)    \n",
    "    root_col = dataframe[root_node] #work_acc col\n",
    "    \n",
    "    s = pd.Series(root_col) \n",
    "    unique_val = s.unique() #0,1\n",
    "    \n",
    "    for i in unique_val:\n",
    "        array = dataframe[root_col == i] \n",
    "        \n",
    "        #dataframe for current unique value\n",
    "        curr = pd.DataFrame(array)\n",
    "        \n",
    "        #now drop this col\n",
    "        curr = curr.drop(root_node , 1)\n",
    "        \n",
    "        recursive_root = buildTree(curr)\n",
    "        \n",
    "        tree_root.add_child(i,recursive_root)\n",
    "    \n",
    "    return tree_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(root):\n",
    "    if len(root.children)==0:\n",
    "#         print \"return root: \",root.root\n",
    "        return\n",
    "    \n",
    "#     print \"Root: \",root.root\n",
    "    \n",
    "    for k,v in root.children.items():\n",
    "#         print \"root: \",root.root, \"key: \",k\n",
    "        traverse(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction from decision tree\n",
    "def predict2(row,root,default=0):\n",
    "    \n",
    "    if(root.isLeaf == True):\n",
    "#         print root.root\n",
    "        return root.result\n",
    "    col=root.root\n",
    "\n",
    "    val=row[col]\n",
    "#     print \"val: \",val\n",
    "    if val in root.children.keys():\n",
    "        return predict2(row,root.children[val])\n",
    "    else:\n",
    "#         val=0\n",
    "        return root.result\n",
    "\n",
    "#helper for predict test. no measures calculated\n",
    "def helper(root, predict_col, df_sample):\n",
    "    df_sample[predict_col] = df_sample.apply(predict2, axis=1, args=(root,0))\n",
    "    return df_sample[predict_col]\n",
    "\n",
    "#this is for test file.\n",
    "def predict(model,model_args,X):\n",
    "    df_sample = pd.read_csv(X)\n",
    "    left_col = helper(model, model_args, df_sample)\n",
    "    return left_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a helper function for making predictions, adds a new col of name predict_col to store the prediction    \n",
    "def helper_validate(df,root, predict_col):\n",
    "    df[predict_col] = df.apply(predict2, axis=1, args=(root,0))\n",
    "    a,p,f,r = findMeasures(df, predict_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMeasures(df, predict_col):\n",
    "    truePos=0\n",
    "    trueNeg=0\n",
    "    falsePos=0\n",
    "    falseNeg=0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "#         print \"index, predict, left,\",index, row[\"prediction\"], row[\"left\"]\n",
    "        if row[predict_col]==0 and row[\"left\"]==0:\n",
    "            trueNeg += 1\n",
    "            \n",
    "        elif row[predict_col]==0 and row[\"left\"]==1:\n",
    "            falseNeg += 1\n",
    "        \n",
    "        elif row[predict_col]==1 and row[\"left\"]==1:\n",
    "            truePos += 1\n",
    "        elif row[predict_col]==1 and row[\"left\"]==0:\n",
    "            falsePos += 1\n",
    "#     print \"TP, TN, FP, FN: \", truePos, trueNeg, falsePos, falseNeg\n",
    "    sumtotal = truePos + trueNeg + falsePos + falseNeg\n",
    "    accuracy = ((float)(truePos + trueNeg))/sumtotal\n",
    "    try:\n",
    "        precision = ((float)(truePos))/(truePos + falsePos)\n",
    "    except:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = ((float)(truePos))/(truePos + falseNeg)\n",
    "    except:\n",
    "        recall = 0\n",
    "    try:\n",
    "        f1_score_den = 1.0/recall + 1.0/precision\n",
    "        f1_score = 2.0/f1_score_den\n",
    "    except:\n",
    "        f1_score=0\n",
    "    print \"A, P, R, F: \", accuracy*100, precision*100, recall*100, f1_score\n",
    "    return accuracy*100, precision*100, recall*100, f1_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = \"../input_data/train.csv\"\n",
    "\n",
    "dataset = pd.read_csv(filename)\n",
    "dataset = dataset.sample(frac=1)\n",
    "train, validate = np.split(dataset, [int(.8*len(dataset))])\n",
    "# print train.shape, validate.shape\n",
    "\n",
    "df_train = pd.DataFrame(train,columns=['Work_accident','promotion_last_5years','sales','salary','left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = buildTree(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Categorical: \n",
      "0    0\n",
      "1    0\n",
      "Name: left, dtype: int64\n",
      "A, P, R, F:  76.0511679644 75.0 0.278164116829 0.00554272517321\n"
     ]
    }
   ],
   "source": [
    "testFile = \"../input_data/sample_test.csv\"\n",
    "pred_label = predict(root, 'left', testFile )\n",
    "print \"Entropy Categorical: \"\n",
    "print pred_label\n",
    "helper_validate(train, root, 'prediction_ent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
